use crate::ir::instructions::{BinaryOp, UnaryOp};
use phf::phf_map;
use std::io::Read;

/// Tokens that will be generated by the lexer.
#[derive(Debug, PartialEq)]
pub(crate) enum Token {
  Int(i64),
  Symbol(String),
  Keyword(Keyword),
  BinaryOp(BinaryOp),
  UnaryOp(UnaryOp),
  Other(char),
  End,
}

/// Keywords of Koopa IR.
#[rustfmt::skip]
#[derive(Clone, Copy, Debug, PartialEq)]
pub(crate) enum Keyword {
  I32,
  Undef, Zeroinit,
  Global, Alloc, Load, Store, Getptr,
  Br, Jump, Call, Ret, Fun, Phi,
}

/// Lexer of Koopa IR.
pub(crate) struct Lexer<T: Read> {
  reader: T,
  // `None` if EOF
  last_char: Option<char>,
}

pub(crate) type Result = std::result::Result<Token, String>;

impl<T: Read> Lexer<T> {
  /// Creates a new `Lexer` from the specific reader.
  pub fn new(reader: T) -> Self {
    Self {
      reader,
      last_char: Some(' '),
    }
  }

  /// Gets the next token from file.
  pub fn next_token(&mut self) -> Result {
    // skip spaces
    while self.last_char.map_or(false, |c| c.is_whitespace()) {
      self.next_char()?;
    }
    // check the last character
    if let Some(c) = self.last_char {
      if c == '/' {
        // skip comments
        self.handle_comment()
      } else if c == '@' || c == '%' {
        // symbols
        self.handle_symbol()
      } else if c.is_alphabetic() {
        // keywords or operands
        self.handle_keyword()
      } else if c.is_numeric() {
        // integer literals
        self.handle_integer()
      } else {
        // other characters
        self.next_char()?;
        Ok(Token::Other(c))
      }
    } else {
      // may be EOF, or other file errors
      Ok(Token::End)
    }
  }

  /// Reads a character from file.
  fn next_char(&mut self) -> std::result::Result<(), String> {
    // NOTE: UTF-8 characters will not be handled here.
    let mut single_char = [0];
    self.last_char = (self
      .reader
      .read(&mut single_char)
      .map_err(|err| format!("{}", err))?
      != 0)
      .then(|| single_char[0] as char);
    Ok(())
  }

  /// Handles integer literals.
  fn handle_integer(&mut self) -> Result {
    // read to string
    let mut num = String::new();
    while self.last_char.map_or(false, |c| c.is_numeric()) {
      num.push(self.last_char.unwrap());
      self.next_char()?;
    }
    // convert to integer
    num
      .parse()
      .map(|i| Token::Int(i))
      .map_err(|_| "invalid integer literal".into())
  }

  /// Handles symbols.
  fn handle_symbol(&mut self) -> Result {
    let tag = self.last_char.unwrap();
    // read the first char to string
    let mut symbol = String::from(tag);
    self.next_char()?;
    // check if number
    if self.last_char.map_or(false, |c| c.is_numeric()) {
      // check if is named symbol
      if tag == '@' {
        return Err("invalid named symbol".into());
      }
      // check the first digit
      let digit = self.last_char.unwrap();
      symbol.push(digit);
      self.next_char()?;
      if digit != '0' {
        // read the rest numbers to string
        while self.last_char.map_or(false, |c| c.is_numeric()) {
          symbol.push(self.last_char.unwrap());
          self.next_char()?;
        }
      }
    } else {
      // read letters, numbers or underscores
      while self
        .last_char
        .map_or(false, |c| c.is_alphanumeric() || c == '_')
      {
        symbol.push(self.last_char.unwrap());
        self.next_char()?;
      }
    }
    Ok(Token::Symbol(symbol))
  }

  /// Handles keywords or operands.
  fn handle_keyword(&mut self) -> Result {
    // read to string
    let mut keyword = String::new();
    while self.last_char.map_or(false, |c| c.is_alphanumeric()) {
      keyword.push(self.last_char.unwrap());
      self.next_char()?;
    }
    // check the string
    if let Some(keyword) = KEYWORDS.get(&keyword) {
      Ok(Token::Keyword(keyword.clone()))
    } else if let Some(op) = BINARY_OPS.get(&keyword) {
      Ok(Token::BinaryOp(op.clone()))
    } else if let Some(op) = UNARY_OPS.get(&keyword) {
      Ok(Token::UnaryOp(op.clone()))
    } else {
      Err("invalid keyword/operator".into())
    }
  }

  /// Handles comments.
  fn handle_comment(&mut self) -> Result {
    // eat '/'
    self.next_char()?;
    // check if is block comment
    if self.last_char == Some('*') {
      self.handle_block_comment()
    } else if self.last_char == Some('/') {
      // skip the current line
      while self.last_char.map_or(false, |c| c != '\r' && c != '\n') {
        self.next_char()?;
      }
      // return the next token
      self.next_token()
    } else {
      Err("invalid comment".into())
    }
  }

  /// Handles block comments.
  fn handle_block_comment(&mut self) -> Result {
    // eat '*'
    self.next_char()?;
    // read until there is '*/' in stream
    let mut star = false;
    while self.last_char.is_some() && !(star && self.last_char == Some('/')) {
      star = self.last_char == Some('*');
      self.next_char()?;
    }
    // check unclosed block comment
    if self.last_char.is_none() {
      Err("comment unclosed at EOF".into())
    } else {
      // eat '/'
      self.next_char()?;
      self.next_token()
    }
  }
}

/// All supported keywords.
static KEYWORDS: phf::Map<&'static str, Keyword> = phf_map! {
  "i32" => Keyword::I32,
  "undef" => Keyword::Undef,
  "zeroinit" => Keyword::Zeroinit,
  "global" => Keyword::Global,
  "alloc" => Keyword::Alloc,
  "load" => Keyword::Load,
  "store" => Keyword::Store,
  "getptr" => Keyword::Getptr,
  "br" => Keyword::Br,
  "jump" => Keyword::Jump,
  "call" => Keyword::Call,
  "ret" => Keyword::Ret,
  "fun" => Keyword::Fun,
  "phi" => Keyword::Phi,
};

/// All supported binary operators.
static BINARY_OPS: phf::Map<&'static str, BinaryOp> = phf_map! {
  "ne" => BinaryOp::NotEq,
  "eq" => BinaryOp::Eq,
  "gt" => BinaryOp::Gt,
  "lt" => BinaryOp::Lt,
  "ge" => BinaryOp::Ge,
  "le" => BinaryOp::Le,
  "add" => BinaryOp::Add,
  "sub" => BinaryOp::Sub,
  "mul" => BinaryOp::Mul,
  "div" => BinaryOp::Div,
  "mod" => BinaryOp::Mod,
  "and" => BinaryOp::And,
  "or" => BinaryOp::Or,
  "xor" => BinaryOp::Xor,
  "shl" => BinaryOp::Shl,
  "shr" => BinaryOp::Shr,
  "sar" => BinaryOp::Sar,
};

/// All supported unary operators.
static UNARY_OPS: phf::Map<&'static str, UnaryOp> = phf_map! {
  "neg" => UnaryOp::Neg,
  "not" => UnaryOp::Not,
};

#[cfg(test)]
mod test {
  use super::*;
  use std::io::Cursor;

  #[test]
  fn read_tokens() {
    let buf = Cursor::new(
      r#"
      // comment
      fun @main(): i32 {
        %entry:
          %ret = alloc i32
          store 0, %ret
          %0 = load %ret
          %1 = add %0, 1
          ret %1
      /*
      block
      comment
      */
      }
      // comment2
      "#,
    );
    let mut lexer = Lexer::new(buf);
    assert_eq!(lexer.next_token(), Ok(Token::Keyword(Keyword::Fun)));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("@main".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Other('(')));
    assert_eq!(lexer.next_token(), Ok(Token::Other(')')));
    assert_eq!(lexer.next_token(), Ok(Token::Other(':')));
    assert_eq!(lexer.next_token(), Ok(Token::Keyword(Keyword::I32)));
    assert_eq!(lexer.next_token(), Ok(Token::Other('{')));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%entry".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Other(':')));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%ret".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Other('=')));
    assert_eq!(lexer.next_token(), Ok(Token::Keyword(Keyword::Alloc)));
    assert_eq!(lexer.next_token(), Ok(Token::Keyword(Keyword::I32)));
    assert_eq!(lexer.next_token(), Ok(Token::Keyword(Keyword::Store)));
    assert_eq!(lexer.next_token(), Ok(Token::Int(0)));
    assert_eq!(lexer.next_token(), Ok(Token::Other(',')));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%ret".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%0".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Other('=')));
    assert_eq!(lexer.next_token(), Ok(Token::Keyword(Keyword::Load)));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%ret".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%1".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Other('=')));
    assert_eq!(lexer.next_token(), Ok(Token::BinaryOp(BinaryOp::Add)));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%0".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Other(',')));
    assert_eq!(lexer.next_token(), Ok(Token::Int(1)));
    assert_eq!(lexer.next_token(), Ok(Token::Keyword(Keyword::Ret)));
    assert_eq!(lexer.next_token(), Ok(Token::Symbol("%1".into())));
    assert_eq!(lexer.next_token(), Ok(Token::Other('}')));
    assert_eq!(lexer.next_token(), Ok(Token::End));
    assert_eq!(lexer.next_token(), Ok(Token::End));
    assert_eq!(lexer.next_token(), Ok(Token::End));
  }
}
